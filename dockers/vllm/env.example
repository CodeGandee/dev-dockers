# Hugging Face Token (Required for gated models)
HUGGING_FACE_HUB_TOKEN=your_token_here

# Model Configuration
MODEL_NAME=Qwen/Qwen2-VL-7B-Instruct
SERVED_MODEL_NAME=qwen2-vl
MAX_MODEL_LEN=8192

# Hardware Configuration
# Number of GPUs to use (e.g., 1, 2, 4, 8)
GPU_COUNT=1
GPU_MEMORY_UTILIZATION=0.95

# Service Configuration
HOST_PORT_API=8000
CONTAINER_PORT_API=8000

# Volume Configuration
# Default: ${HOME}/.cache/huggingface -> /root/.cache/huggingface
HOST_VOLUME_HF_CACHE=/home/user/.cache/huggingface
CONTAINER_VOLUME_HF_CACHE=/root/.cache/huggingface
